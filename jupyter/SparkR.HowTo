R and SparkR practice on Cloudera Cluster

R Location
/opt/cloudera/parcels/Anaconda/bin/R

Installation

install.packages("sparklyr")
install.packages("devtools")
spark_install(version = "1.6.2")  ##This is for local testing/dev purpose, optional

** package ‘devtools’ successfully unpacked and MD5 sums checked
** R
** inst
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
*** copying figures
** building package indices
** installing vignettes
** testing if installed package can be loaded
* DONE (devtools)

# sudo/root is needed to install libraries/packages
Start R as root:
[root@mycluster code]# /opt/cloudera/parcels/Anaconda/bin/R
Install rstudio/sparklyr with devtools
devtools::install_github("rstudio/sparklyr")

[root@mycluster code]# /opt/cloudera/parcels/Anaconda/bin/R
> install.packages("sparklyr")
--- Please select a CRAN mirror for use in this session ---
Secure CRAN mirrors

 1: 0-Cloud [https]                   2: Algeria [https]
 3: Australia (Canberra) [https]      4: Australia (Melbourne 1) [https]
61: USA (IA) [https]                 62: USA (KS) [https]
63: USA (MI 1) [https]               64: USA (NY) [https]

Selection: 61
also installing the dependencies ‘config’, ‘r2d3’, ‘rappdirs’, ‘forge’

trying URL 'https://mirror.las.iastate.edu/CRAN/src/contrib/config_0.3.tar.gz'
Content type 'application/x-gzip' length 12344 bytes (12 KB)
==================================================
downloaded 12 KB

trying URL 'https://mirror.las.iastate.edu/CRAN/src/contrib/r2d3_0.2.2.tar.gz'
Content type 'application/x-gzip' length 2371864 bytes (2.3 MB)
==================================================
downloaded 2.3 MB

trying URL 'https://mirror.las.iastate.edu/CRAN/src/contrib/rappdirs_0.3.1.tar.gz'
Content type 'application/x-gzip' length 12838 bytes (12 KB)
==================================================
downloaded 12 KB

trying URL 'https://mirror.las.iastate.edu/CRAN/src/contrib/forge_0.1.0.tar.gz'
Content type 'application/x-gzip' length 4377 bytes
==================================================
downloaded 4377 bytes

trying URL 'https://mirror.las.iastate.edu/CRAN/src/contrib/sparklyr_0.9.2.tar.gz'
Content type 'application/x-gzip' length 3805842 bytes (3.6 MB)
==================================================
downloaded 3.6 MB

* installing *source* package ‘config’ ...
** package ‘config’ successfully unpacked and MD5 sums checked
** R
** inst
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded
* DONE (config)
* installing *source* package ‘r2d3’ ...
** package ‘r2d3’ successfully unpacked and MD5 sums checked
** R
** inst
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded
* DONE (r2d3)
* installing *source* package ‘rappdirs’ ...
** package ‘rappdirs’ successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I"/opt/cloudera/parcels/Anaconda/lib/R/include" -DNDEBUG   -I/opt/cloudera/parcels/Anaconda/include   -fpic  -I/opt/cloudera/parcels/Anaconda/include  -c win-path.c -o win-path.o
gcc -std=gnu99 -shared -L/opt/cloudera/parcels/Anaconda/lib/R/lib -Wl,-rpath,/opt/cloudera/parcels/Anaconda/lib -L/opt/cloudera/parcels/Anaconda/lib -L/opt/cloudera/parcels/Anaconda/lib -lgfortran -o rappdirs.so win-path.o -L/opt/cloudera/parcels/Anaconda/lib/R/lib -lR
installing to /opt/cloudera/parcels/Anaconda-4.2.0/lib/R/library/rappdirs/libs
** R
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
* DONE (rappdirs)
* installing *source* package ‘forge’ ...
** package ‘forge’ successfully unpacked and MD5 sums checked
** R
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
* DONE (forge)
* installing *source* package ‘sparklyr’ ...
** package ‘sparklyr’ successfully unpacked and MD5 sums checked
** R
** inst
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
* DONE (sparklyr)

The downloaded source packages are in
        ‘/tmp/RtmpZiHtPV/downloaded_packages’
>

#Upgrade sparklyr
devtools::install_github("rstudio/sparklyr")

The following packages will be installed or upgraded:
cli         (1.0.0   -> 1.0.1  ) [CRAN]
digest      (0.6.15  -> 0.6.18 ) [CRAN]
dplyr       (0.7.6   -> 0.7.7  ) [CRAN]
fansi       (0.2.3   -> 0.4.0  ) [CRAN]
htmlwidgets (1.2     -> 1.3    ) [CRAN]
later       (0.7.3   -> 0.7.5  ) [CRAN]
mime        (0.5     -> 0.6    ) [CRAN]
pkgconfig   (2.0.1   -> 2.0.2  ) [CRAN]
R6          (2.2.2   -> 2.3.0  ) [CRAN]
Rcpp        (0.12.18 -> 0.12.19) [CRAN]
rlang       (0.2.1   -> 0.3.0.1) [CRAN]
rstudioapi  (0.7     -> 0.8    ) [CRAN]
shiny       (1.1.0   -> 1.2.0  ) [CRAN]
tidyr       (0.8.1   -> 0.8.2  ) [CRAN]
tidyselect  (0.2.4   -> 0.2.5  ) [CRAN]
xtable      (1.8-2   -> 1.8-3  ) [CRAN]
* installing *source* package ‘sparklyr’ ...
** R
** inst
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
* DONE (sparklyr)

Local connect to Spark Context
library(sparklyr)
library(dplyr)
sc<-spark_connect(master=”local”)

> library(sparklyr)
> library(dplyr)
> sc<-spark_connect(master='local')
* Using Spark: 1.6.2
>

Remote connect to Spark Context:

#Remember to kinit first in order to get a valid ticket

[rxie@mycluster code]$ kinit
Password for rxie@NOVANTAS.PRI:

[rxie@mycluster code]$ /opt/cloudera/parcels/Anaconda/bin/R

R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(sparklyr)
> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> sc1<-spark_connect(master="yarn-client",spark_home="/opt/cloudera/parcels/SPARK2/lib/spark2", app_name="test")
> src_tbls(sc1)
 [1] "al2_test"
 [2] "as_avro"
 [3] "blank_table"
 [4] "bmo_dim_active"
 [5] "bmo_dim_costcenter"
 [6] "bmo_dim_positions"
 [7] "bmo_dim_positions_kb"
 [8] "bmo_dim_trxntype"
 [9] "bmo_fact_trxn"
[10] "bnsc_dim_active"
[11] "bnsc_dim_costcenter"
[12] "bnsc_dim_positions"
[13] "bnsc_dim_trxntype"
[14] "bnsc_fact_fte"
[15] "bnsc_fact_trxn"
[16] "bom_dim_trxntype"
[17] "build1"
[18] "build2"
[19] "build3"
[20] "build4"
[21] "build5"
[22] "customers"
[23] "dimdate"
[24] "harryperformancemeasuringtmp"
[25] "modelerrortmp"
[26] "modelerrortmp2"
[27] "mtz_temp_922a"
[28] "nullmetric2"
[29] "nullmetric3"
[30] "nullmetric4"
[31] "outputtable"
[32] "sample_07"
[33] "sample_08"
[34] "ss_table1"
[35] "ss_table2"
[36] "tabletoberemoved2"
[37] "tbl_balcustflowfinalhistm_wfgo_subset_date_rename"
[38] "tbl_sqlalchemy_ds"
[39] "test_ks2"
[40] "toberemovedtable1"
[41] "v5_tdct_customer_first_product_version4"
[42] "v8_bnsc_customer_first_product_version4"
[43] "v9_rbc_customer_first_product_version4"
[44] "web_logs"
[45] "yellow_tripdata_201701"
> 
Connecting through Livy
Livy enables remote connections to Apache Spark clusters. Connecting to Spark clusters through Livy is under experimental development in sparklyr. Please post any feedback or questions as a GitHub issue as needed.
Before connecting to Livy, you will need the connection information to an existing service running Livy. Otherwise, to test livyin your local environment, you can install it and run it locally as follows:
livy_install()
livy_service_start()
To connect, use the Livy service address as master and method = "livy" in spark_connect. Once connection completes, use sparklyr as usual, for instance:
sc <- spark_connect(master = "http://localhost:8998", method = "livy")
copy_to(sc, iris)
## Source:   query [150 x 5]
## Database: spark connection master=http://localhost:8998 app= local=FALSE
## 
##    Sepal_Length Sepal_Width Petal_Length Petal_Width Species
##           <dbl>       <dbl>        <dbl>       <dbl>   <chr>
## 1           5.1         3.5          1.4         0.2  setosa
## 2           4.9         3.0          1.4         0.2  setosa
## 3           4.7         3.2          1.3         0.2  setosa
## 4           4.6         3.1          1.5         0.2  setosa
## 5           5.0         3.6          1.4         0.2  setosa
## 6           5.4         3.9          1.7         0.4  setosa
## 7           4.6         3.4          1.4         0.3  setosa
## 8           5.0         3.4          1.5         0.2  setosa
## 9           4.4         2.9          1.4         0.2  setosa
## 10          4.9         3.1          1.5         0.1  setosa
## # ... with 140 more rows
spark_disconnect(sc)
Once you are done using livy locally, you should stop this service with:
livy_service_stop()

Visualization

Testing script

R in Jupyter

